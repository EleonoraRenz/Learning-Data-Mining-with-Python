{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining CS 619, Spring 2018 - Eleonora Renz\n",
    "\n",
    "### Week 4 - Chapter 4\n",
    "\n",
    "## Recommendeing Movies Using Affinity Analysis\n",
    "\n",
    "#### Algorithms for affinity analysis\n",
    "\n",
    "The total possible number of rules is <i>2n - 1</i>.<br>\n",
    "<b>Apriori algorithm</b> addresses the\n",
    "exponential problem of creating sets of items that occur frequently within a database, called\n",
    "<i>frequent itemsets</i>.\n",
    "<br>Similar algorithms are <b>Eclat</b> and <b>FP-growth</b>.\n",
    "\n",
    "#### Obtaining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#data_folder = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"DataMining_Spring2018\", \"Data\", \"ml-100k\")\n",
    "data_folder = \"Data/ml-100k\" \n",
    "ratings_filename = os.path.join(data_folder, \"u.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>1997-12-04 15:55:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-04-04 19:22:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1997-11-07 07:18:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1997-11-27 05:02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-02-02 05:33:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating            Datetime\n",
       "0     196      242       3 1997-12-04 15:55:49\n",
       "1     186      302       3 1998-04-04 19:22:22\n",
       "2      22      377       1 1997-11-07 07:18:36\n",
       "3     244       51       2 1997-11-27 05:02:03\n",
       "4     166      346       1 1998-02-02 05:33:16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings = pd.read_csv(ratings_filename, delimiter=\"\\t\", header=None, names = [\"UserID\", \"MovieID\", \"Rating\", \"Datetime\"])\n",
    "\n",
    "all_ratings[\"Datetime\"] = pd.to_datetime(all_ratings['Datetime'], unit='s')\n",
    "\n",
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the Apriori algorithm and its implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Favorable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62</td>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>1997-11-12 22:07:14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>286</td>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>1997-11-17 15:38:45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>1997-10-05 09:05:40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-03-27 21:59:54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>224</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-02-21 23:40:57</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserID  MovieID  Rating            Datetime  Favorable\n",
       "10      62      257       2 1997-11-12 22:07:14      False\n",
       "11     286     1014       5 1997-11-17 15:38:45       True\n",
       "12     200      222       5 1997-10-05 09:05:40       True\n",
       "13     210       40       3 1998-03-27 21:59:54      False\n",
       "14     224       29       3 1998-02-21 23:40:57      False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings[\"Favorable\"] = all_ratings[\"Rating\"] > 3\n",
    "\n",
    "all_ratings[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MovieID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Favorable\n",
       "MovieID           \n",
       "50           100.0\n",
       "100           89.0\n",
       "258           83.0\n",
       "181           79.0\n",
       "174           74.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = all_ratings[all_ratings['UserID'].isin(range(200))]\n",
    "\n",
    "favorable_ratings_mask = ratings['Favorable']\n",
    "favorable_ratings = ratings[favorable_ratings_mask]\n",
    "\n",
    "favorable_reviews_by_users = dict((k, frozenset(v.values)) for k, v in favorable_ratings.groupby(\"UserID\")[\"MovieID\"])\n",
    "\n",
    "num_favorable_by_movie = ratings[[\"MovieID\", \"Favorable\"]].groupby(\"MovieID\").sum()\n",
    "\n",
    "# View top 5 movie list\n",
    "num_favorable_by_movie.sort_values(by=\"Favorable\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking into the basics of the Apriori algorithm\n",
    "\n",
    "1. Create initial frequent itemsets by placing each item in its own itemset. Only\n",
    "items with at least the minimum support are used in this step.<br>\n",
    "2. New candidate itemsets are created from the most recently discovered frequent\n",
    "itemsets by finding supersets of the existing frequent itemsets.<br>\n",
    "3. All candidate itemsets are tested to see if they are frequent. If a candidate is not\n",
    "frequent then it is discarded. If there are no new frequent itemsets from this step,\n",
    "go to the last step.<br>\n",
    "4. Store the newly discovered frequent itemsets and go to the second step.<br>\n",
    "5. Return all of the discovered frequent itemsets.\n",
    "\n",
    "#### Implementing the Apriori alogrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequent_itemsets = {}\n",
    "\n",
    "min_support = 50\n",
    "\n",
    "frequent_itemsets[1] = dict((frozenset((movie_id,)), row[\"Favorable\"])\n",
    "                            for movie_id, row in num_favorable_by_movie.iterrows()\n",
    "                            if row[\"Favorable\"] > min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_frequent_itemsets(favorable_reviews_by_user, k_1_itemsets,min_support):\n",
    "    \"\"\" Function that takes the newly discovered frequent itemsets, creates the supersets, \n",
    "        and then tests if they are frequent\"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for user, reviews in favorable_reviews_by_users.items():\n",
    "        for itemset in k_1_itemsets:\n",
    "            if itemset.issubset(reviews):\n",
    "                for other_reviewed_movie in reviews - itemset:\n",
    "                    current_superset = itemset | frozenset((other_reviewed_movie,))\n",
    "                    counts[current_superset] += 1\n",
    "    return dict([(itemset, frequency) for itemset, frequency in counts.items() if frequency >= min_support])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 93 frequent itemsets of length 2\n",
      "I found 295 frequent itemsets of length 3\n",
      "I found 593 frequent itemsets of length 4\n",
      "I found 785 frequent itemsets of length 5\n",
      "I found 677 frequent itemsets of length 6\n",
      "I found 373 frequent itemsets of length 7\n",
      "I found 126 frequent itemsets of length 8\n",
      "I found 24 frequent itemsets of length 9\n",
      "I found 2 frequent itemsets of length 10\n",
      "Did not find any frequent itemsets of length 11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for k in range(2,20):\n",
    "    # Generate candidates of length k, using the frequent itemsets of length k-1\n",
    "    # Only store the freuqent itemsets\n",
    "    cur_frequent_itemsets = find_frequent_itemsets(favorable_reviews_by_users, frequent_itemsets[k-1], min_support)\n",
    "    if len(cur_frequent_itemsets) == 0:\n",
    "        print(\"Did not find any frequent itemsets of length {}\".format(k))\n",
    "        sys.stdout.flush()\n",
    "        break\n",
    "    else:\n",
    "        print(\"I found {} frequent itemsets of length {}\".format(len(cur_frequent_itemsets), k))\n",
    "        sys.stdout.flush()\n",
    "        frequent_itemsets[k] = cur_frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting association rules\n",
    "\n",
    "A frequent itemset is a set of items with a minimum support, while an association rule has a premise\n",
    "and a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(frozenset(), 1), (frozenset(), 7), (frozenset(), 9), (frozenset(), 50), (frozenset(), 56)]\n"
     ]
    }
   ],
   "source": [
    "candidate_rules = []\n",
    "for itemset_legth, itemset_counts in frequent_itemsets.items():\n",
    "    for itemset in itemset_counts.keys():\n",
    "        for conclusion in itemset:\n",
    "            premise = itemset -set((conclusion,))\n",
    "            candidate_rules.append((premise, conclusion))\n",
    "\n",
    "print(candidate_rules[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate confidence \n",
    "\n",
    "correct_counts = defaultdict(int)\n",
    "incorrect_counts = defaultdict(int)\n",
    "\n",
    "for user, reviews in favorable_reviews_by_users.items():\n",
    "    for candidate_rule in candidate_rules:\n",
    "        premise, conclusion = candidate_rule\n",
    "        if premise.issubset(reviews):\n",
    "            if conclusion in reviews:\n",
    "                correct_counts[candidate_rule] += 1\n",
    "            else:\n",
    "                incorrect_counts[candidate_rule] += 1\n",
    "            \n",
    "rule_confidence = {candidate_rule:\n",
    "                  (correct_counts[candidate_rule] / float(correct_counts[candidate_rule] + incorrect_counts[candidate_rule]))\n",
    "                  for candidate_rule in candidate_rules}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: #1\n",
      "Rule: If a person recommends frozenset({98, 181}) they will also recommend 50\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule: #2\n",
      "Rule: If a person recommends frozenset({172, 79}) they will also recommend 174\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule: #3\n",
      "Rule: If a person recommends frozenset({258, 172}) they will also recommend 174\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule: #4\n",
      "Rule: If a person recommends frozenset({1, 181, 7}) they will also recommend 50\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule: #5\n",
      "Rule: If a person recommends frozenset({1, 172, 7}) they will also recommend 174\n",
      " - Confidence: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "sorted_confidence = sorted(rule_confidence.items(), key=itemgetter(1), reverse=True)\n",
    "for index in range(5):\n",
    "    print(\"Rule: #{0}\".format(index + 1))\n",
    "    premise, conclusion = sorted_confidence[index][0]\n",
    "    print(\"Rule: If a person recommends {0} they will also recommend {1}\".format(premise, conclusion))\n",
    "    print(\" - Confidence: {0:.3f}\".format(rule_confidence[(premise, conclusion)]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_name_filename = os.path.join(data_folder, \"u.item\")\n",
    "movie_name_data = pd.read_csv(movie_name_filename, delimiter=\"|\", header=None, encoding = \"mac-roman\")\n",
    "movie_name_data.columns = [\"MovieID\", \"Title\", \"Release Date\", \"Video Release\", \"IMBD\", \"<UNK>\", \"Action\", \"Adeventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "\n",
    "def get_movie_name(movie_id):\n",
    "    title_object = movie_name_data[movie_name_data[\"MovieID\"] == movie_id][\"Title\"]\n",
    "    title = title_object.values[0]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule #1\n",
      "Rule: If a person recommends Silence of the Lambs, The (1991), Return of the Jedi (1983) they will also recommend Star Wars (1977)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #2\n",
      "Rule: If a person recommends Empire Strikes Back, The (1980), Fugitive, The (1993) they will also recommend Raiders of the Lost Ark (1981)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #3\n",
      "Rule: If a person recommends Contact (1997), Empire Strikes Back, The (1980) they will also recommend Raiders of the Lost Ark (1981)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #4\n",
      "Rule: If a person recommends Toy Story (1995), Return of the Jedi (1983), Twelve Monkeys (1995) they will also recommend Star Wars (1977)\n",
      " - Confidence: 1.000\n",
      "\n",
      "Rule #5\n",
      "Rule: If a person recommends Toy Story (1995), Empire Strikes Back, The (1980), Twelve Monkeys (1995) they will also recommend Raiders of the Lost Ark (1981)\n",
      " - Confidence: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(5):\n",
    "    print(\"Rule #{0}\".format(index + 1))\n",
    "    premise, conclusion = sorted_confidence[index][0]\n",
    "    premise_names = \", \".join(get_movie_name(idx) for idx in premise)\n",
    "    conclusion_name = get_movie_name(conclusion)\n",
    "    print(\"Rule: If a person recommends {0} they will also recommend {1}\".format(premise_names, conclusion_name))\n",
    "    print(\" - Confidence: {0:.3f}\".format(rule_confidence[(premise, conclusion)]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluationg the association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = all_ratings[~all_ratings['UserID'].isin(range(200))]\n",
    "test_favorable = test_dataset[test_dataset[\"Favorable\"]]\n",
    "test_favorable_by_users = dict((k, frozenset(v.values)) for k, v in test_favorable.groupby(\"UserID\")[\"MovieID\"])\n",
    "\n",
    "correct_counts = defaultdict(int)\n",
    "incorrect_counts = defaultdict(int)\n",
    "for user, reviews in test_favorable_by_users.items():\n",
    "    for candidate_rule in candidate_rules:\n",
    "        premise, conclusion = candidate_rule\n",
    "        if premise.issubset(reviews):\n",
    "            if conclusion in reviews:\n",
    "                correct_counts[candidate_rule] += 1\n",
    "            else:\n",
    "                incorrect_counts[candidate_rule] += 1\n",
    "            \n",
    "test_confidence = {candidate_rule: (correct_counts[candidate_rule] / float(correct_counts[candidate_rule] + incorrect_counts[candidate_rule]))\n",
    "                  for candidate_rule in rule_confidence}\n",
    "sorted_test_confidence = sorted(test_confidence.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "for index in range(10):\n",
    "    print(\"Rule #{0}\".format(index + 1))\n",
    "    premise, conclusion = sorted_confidence[index][0]\n",
    "    premise_names = \", \".join(get_movie_name(idx) for idx in premise)\n",
    "    conclusion_name = get_movie_name(conclusion)\n",
    "    print(\"Rule: If a person recommends {0} they will also recommend {1}\".format(premise_names, conclusion_name))\n",
    "    print(\" - Train Confidence: {0:.3f}\".format(rule_confidence.get((premise, conclusion), -1)))\n",
    "    print(\" - Test Confidence: {0:.3f}\".format(test_confidence.get((premise, conclusion), -1)))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
